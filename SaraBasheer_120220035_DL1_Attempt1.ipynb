{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwIi0MEXB2Qa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# CIFAR-10 data loading\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Use 5% of training data (2,500 images)\n",
        "subset_indices = np.random.choice(len(trainset), size=int(0.05 * len(trainset)), replace=False)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=False, sampler=SubsetRandomSampler(subset_indices))\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7evVXlSdB7B_"
      },
      "outputs": [],
      "source": [
        "# AlexNet\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9tb-2jlkCKw5"
      },
      "outputs": [],
      "source": [
        "# VGG (and variants)\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, num_classes=10, batch_norm=False):\n",
        "        super(VGG, self).__init__()\n",
        "        cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for v in cfg:\n",
        "            if v == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "                if batch_norm:\n",
        "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "                else:\n",
        "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "                in_channels = v\n",
        "        self.features = nn.Sequential(*layers)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2_W9FMbLCO7V"
      },
      "outputs": [],
      "source": [
        "# VGG-8\n",
        "class VGG8(nn.Module):\n",
        "    def __init__(self, num_classes=10, batch_norm=False):\n",
        "        super(VGG8, self).__init__()\n",
        "        cfg = [64, 'M', 128, 'M', 256, 256, 'M', 512, 'M']\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for v in cfg:\n",
        "            if v == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "                if batch_norm:\n",
        "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "                else:\n",
        "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "                in_channels = v\n",
        "        self.features = nn.Sequential(*layers)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 14 * 14, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2bGkIYomCSlT"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_model(model, trainloader, testloader, epochs=1):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    scaler = GradScaler()\n",
        "    train_losses, val_losses, train_accs, val_accs, times = [], [], [], [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        train_losses.append(running_loss / len(trainloader))\n",
        "        train_accs.append(100 * correct / total)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                with autocast():\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        val_losses.append(val_loss / len(testloader))\n",
        "        val_accs.append(100 * correct / total)\n",
        "        times.append(time.time() - start_time)\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]:.3f}, Train Acc: {train_accs[-1]:.2f}%, Val Loss: {val_losses[-1]:.3f}, Val Acc: {val_accs[-1]:.2f}%')\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p76PrtTtCX9s"
      },
      "outputs": [],
      "source": [
        "# Test accuracy\n",
        "def test_accuracy(model, testloader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Visualize feature maps\n",
        "def visualize_feature_maps(model, layer_idx, input_image, filename):\n",
        "    model.eval()\n",
        "    x = input_image.unsqueeze(0).to(device)\n",
        "    for idx, layer in enumerate(model.features):\n",
        "        x = layer(x)\n",
        "        if idx == layer_idx:\n",
        "            break\n",
        "    feature_maps = x.squeeze(0).detach().cpu().numpy()\n",
        "    num_maps = min(feature_maps.shape[0], 8)\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(num_maps):\n",
        "        plt.subplot(1, num_maps, i+1)\n",
        "        plt.imshow(feature_maps[i], cmap='viridis')\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "\n",
        "# Plot curves\n",
        "def plot_curves(train_losses, val_losses, train_accs, val_accs, title, filename):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.title(f'{title} Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accs, label='Train Acc')\n",
        "    plt.plot(val_accs, label='Val Acc')\n",
        "    plt.title(f'{title} Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.savefig(filename)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX0QgLnUCcP8",
        "outputId": "fec9c9f4-d55c-403b-a416-abbac20811c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training AlexNet...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-0a4a31d24801>:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "<ipython-input-6-0a4a31d24801>:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "<ipython-input-6-0a4a31d24801>:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 2.303, Train Acc: 9.84%, Val Loss: 2.303, Val Acc: 10.00%\n",
            "\n",
            "Training VGG...\n",
            "Epoch 1, Train Loss: 2.303, Train Acc: 8.68%, Val Loss: 2.303, Val Acc: 10.00%\n",
            "\n",
            "Training VGG_BN...\n",
            "Epoch 1, Train Loss: 2.386, Train Acc: 15.84%, Val Loss: 6.876, Val Acc: 17.35%\n",
            "\n",
            "Training VGG8...\n",
            "Epoch 1, Train Loss: 2.302, Train Acc: 12.32%, Val Loss: 2.297, Val Acc: 13.64%\n",
            "\n",
            "Performance Comparison:\n",
            "Model      Test Acc (%) Time/Epoch (s)  Overfitting \n",
            "AlexNet    10.00        27.81           -0.16       \n",
            "VGG        10.00        58.97           -1.32       \n",
            "VGG_BN     17.34        66.38           -1.51       \n",
            "VGG8       13.64        42.94           -1.32       \n"
          ]
        }
      ],
      "source": [
        "# Main execution\n",
        "models = {\n",
        "    'AlexNet': AlexNet().to(device),\n",
        "    'VGG': VGG(batch_norm=False).to(device),\n",
        "    'VGG_BN': VGG(batch_norm=True).to(device),\n",
        "    'VGG8': VGG8(batch_norm=False).to(device)\n",
        "}\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f'\\nTraining {name}...')\n",
        "    train_losses, val_losses, train_accs, val_accs, times = train_model(model, trainloader, testloader, epochs=1)\n",
        "    test_acc = test_accuracy(model, testloader)\n",
        "    results[name] = {'train_losses': train_losses, 'val_losses': val_losses, 'train_accs': train_accs, 'val_accs': val_accs, 'times': times, 'test_acc': test_acc}\n",
        "    plot_curves(train_losses, val_losses, train_accs, val_accs, name, f'{name}_curves.png')\n",
        "    input_image = trainset[0][0]\n",
        "    visualize_feature_maps(model, layer_idx=0, input_image=input_image, filename=f'{name}_feature_maps.png')\n",
        "\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(f\"{'Model':<10} {'Test Acc (%)':<12} {'Time/Epoch (s)':<15} {'Overfitting':<12}\")\n",
        "for name, res in results.items():\n",
        "    avg_time = np.mean(res['times'])\n",
        "    overfitting = res['train_accs'][-1] - res['val_accs'][-1]\n",
        "    print(f\"{name:<10} {res['test_acc']:<12.2f} {avg_time:<15.2f} {overfitting:<12.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
